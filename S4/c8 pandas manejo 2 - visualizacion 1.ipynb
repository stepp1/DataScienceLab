{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA6202: Laboratorio de Ciencia de Datos\n",
    "\n",
    "**Profesor: Nicolás Caro**\n",
    "\n",
    "**20/04/2020 - C8 S4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de Datos 2 y Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es Habitual que la información se encuentre dispersa en distintas fuentes y que por tanto, se requiera unificar el contenido. Si bien esto representa una componente importante del análisis de datos, el proceso no termina ahí, pues es necesario agregar, categorizar, agrupar y aplicar funciones a las agrupaciones logradas. Tales funciones se traducen en calculo de estadísticas, uso de tablas pivote, generación de visualizaciones entre otras tareas. \n",
    "\n",
    "En está cátedra, nos centraremos en las herramientas que facilitan los procesos de unificación, agrupación y visualización presentes en el flujo de trabajo de ciencia de datos. Tales herramientas se cimientan en `pandas` y `matplotlib`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera Parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unificación de datasets\n",
    "\n",
    "La información contenida en los objetos `Series` y `DataFrame` puede ser combinada de distintas maneras. Una de ellas es por medio de *merging* o *fusión*, este tipo de operación permiten combinar datasets al enlazar filas según uno o más campos 'llave'. \n",
    "\n",
    "La función `merge` de pandas permite implementar estos procedimientos.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se generan 2 objetos `DataFrame` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({'llaves': list('abdabhakl'), 'data': range(9)})\n",
    "\n",
    "# Se etiquetan los indices (ind) y columnas (columns)\n",
    "df1.index.name = 'ind' \n",
    "df1.columns.name ='columns'\n",
    "\n",
    "df1.sort_values(by = 'llaves', inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene un nuevo dataframe por reindex del primero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.reindex(index = [1,3,5])\n",
    "\n",
    "# Se alteran cierto valores\n",
    "df2.data = [10, 30, 50]\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se estudia la relación *muchos a uno* (*many to one*). Acá `df1` posee 3 instancias de la llave 'a' y 2 de 'b', por su parte `df2` posee solo una copia de cada 'llave'. Al utilizar `merge` sobre las llaves se obtiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2, on = 'llaves')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tanto `df1` como `df2` comparten la columna `llaves` y merge procese a unificar ambos datasets utilizando la columna llave como punto de union. Observe que se preservan los valores de `df1` en `data_x` y de `df2` en `data_y`. \n",
    "\n",
    "Si los dataframes a fusionar no poseen columnas en común, es posible entregar los argumentos `left_on` para la llave a utilizar en el dataframe izquierdo (como argumento de `merge`), de manera análoga se debe introducir `rigth_on`. \n",
    "\n",
    "Se crean dos nuevos dataframes sin columnas en común"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.copy()\n",
    "\n",
    "# Se generan las nuevas llaves\n",
    "df3['l_llave'] = df3.llaves\n",
    "df3['data_1'] = df3.data\n",
    "\n",
    "# Se eliminan las columnas antiguas\n",
    "df3.drop(['data','llaves'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Se repite el proeso para df4\n",
    "\n",
    "df4 = df2.copy()\n",
    "df4['r_llave'] = df2.llaves\n",
    "df4['data_2'] = df2.data\n",
    "df4.drop(['data','llaves'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a fusionar `df3` y `df4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df3,df4, left_on = 'l_llave', right_on= 'r_llave')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperando (salvo suplcación de llave) el dataframe anterior. `merge` opera por defecto haciendo uniones *internas* (*inner join*), esto significa, hay llaves en alguna dataset sin valor asociado en el otro, se omiten.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se comprueba lo anterior, para ello se agregan dos nuevas filas a `df3`. Observe que la opción `ignore_index` permite agregar diccionarios al final de `df3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.append({'data_1':'y', 'l_llave':100}, ignore_index=True)\n",
    "df3 = df3.append({'data_1':'z', 'l_llave':200}, ignore_index=True)\n",
    "df3.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repite el proceso de unión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df3,df4, left_on = 'l_llave', right_on= 'r_llave')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que comprueba el resultado. \n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "1. Utilice los objetos `DataFrame` `df3` y `df4` para explorar las opciones de `pd.merge(how = opt)` donde `opt` pertenece a `{'left', 'right', 'outer', 'inner'}`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tipo de unón *muchos a muchos* (*many to many*).Se comporta de manera distinta. En este caso, se genera un producto cartesiano de las filas. \n",
    "\n",
    "**Ejemplo** \n",
    "\n",
    "Se agregan valores a `df4`, para ello se crea un daaframe con los valores a agregar, se declaran sus columnas y se agrega al final de `df4`. Observe la opción `ignore_index = True` esta permite omitir los índices de `df_pivot` y continuar con los de `df4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = pd.DataFrame(\n",
    "    [['a', 300], ['a', 301], ['h', 500], ['h', 501], ['b', 100]],\n",
    "    columns=df4.columns)\n",
    "\n",
    "# Observe que append en dataframes no opera como en listas (no es inplace)\n",
    "df4 = df4.append(df_pivot, ignore_index=True)\n",
    "df4.sort_values(by = 'r_llave', inplace=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a unir `df3` con `df4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df3,df4, left_on='l_llave', right_on='r_llave', how= 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hay 3 instancias de 'a' en `df3` y 3 instancias de 'a' en `df4`, se tienen un total de 9 entradas relacioandas a 'a' en la unión (desde el índice 0 al 8). Esto se puede intepretar de la siguiente manera: \n",
    "\n",
    "Cuando hay **una** columna de llaves, es decir, independiente del nombre de las columnas `left_on` y `right_on`, se escoge una por dataset. Se tendrá en este caso, que la  unión **muchos a muchos** repetirá los identificadores de la columna de llaves, tantas veces como lo requiera el producto cartesiano de los valores asociados a tales llaves. Por tal motivo, en el ejemplo anterior, aparecen 9 instancias de 'a'.\n",
    "\n",
    "Por otra parte, `pd.merge()` permite la unión de datasets proporcionando **más de una** columna llave por dataset. En este caso, los identificadores a utilizar, pasan a ser elementos del producto cartesiano entre los identificadores de cada columna de llaves proporcionada, los cuales (identificadores), serán repetidos, tantas veces como el producto cartesiano de sus valoes asociados lo requiera. \n",
    "\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se estudia la unión de datasets *muchos a muchos* proporcionando múltiples  columnas de llaves. Para ello se definen los siguientes dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.DataFrame({\n",
    "    'llave_1': ['a', 'a', 'b'],\n",
    "    'llave_2': [5, 7, 5],\n",
    "    'data_m': [10, 20, 30]\n",
    "})\n",
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.DataFrame({\n",
    "    'llave_1': ['a', 'a', 'b', 'b'],\n",
    "    'llave_2': [5, 5, 5, 7],\n",
    "    'data_n': [100, 200, 300, 400]\n",
    "})\n",
    "df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a unir ambos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_m,df_n, on = ['llave_1','llave_2'], how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al elegir `how = 'outer'` se realiza una *unión externa*, a diferencia de la unión interna, acá se agregan valores nulos cuando no se tiene la información (en vez de omitr la fila).\n",
    "\n",
    "\n",
    "En este ejemplo se aprecia que el producto cartesiano entre `llave_1` y `llave_2` corresponde a: \n",
    "\n",
    " * 'a',5\n",
    " * 'a',7\n",
    " * 'b',5\n",
    " * 'b',7\n",
    " \n",
    "Se observa que para el par 'a',5  el producto cartesiano de sus valores asociados es:\n",
    "\n",
    "* 10, 100\n",
    "* 10, 200\n",
    "\n",
    "mientras que para 'a',7 solo existe un valor en `df_m` y es nulo en `df_n`. Se continua con dicha lógica hasta completar la tabla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Cargue los datos `'data/timesData.csv'` en la variable `df` indexe por año y ranking,\n",
    "\n",
    "2. Genere una función `data_process(df, year,n)` que procese al dataset `df` de manera tal, que retorne un sub-dataset con las primeras `n` universidades (según ranking), con las columnas 'university_name', 'teaching' y 'research'. Además debe tener un indice múlti - nivel, donde 'country' sea el nivel más externo y 'wolrd_rank' se el nivel interno. *Hint*: Investigue el método `.set_index()`.\n",
    "\n",
    "3. Utilice `data_process()` para generar datasets de los años 2011 y 2016 para `n=20` cada uno.\n",
    "\n",
    "4. Haga una unión interna entre ambos datasets según los multi - indices, el resultado de esto le permitirá saber que universidades han mantenido su puesto, por país, al tiempo que puede verificar modificaciones en los puntajes de enseñanza e investigación. Observe que para esto deberá utilizar los argumentos `left_index` y `right_index`. Finalmente deduzca que la unión de datasets por indexación múltiple, obedece e mismo principio que la unión por múltiples columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro tipo de unificación de datos es la concatenación, gracias a la indexación de pandas, es posible concatenar objetos con distintas indexaciones por medio de uniones internas (solo mantener datos ejes en común), elegir ejes de concatenación, concatenar *slices* de dataframes para componer otro, etc.\n",
    "\n",
    "La función `pd.concat()` permite todo lo anterior y su funcionamiento es bastante intuitivo.\n",
    "\n",
    "**Ejemplo** \n",
    "\n",
    "Se estudia la concatenación en series, para ello se definen `serie_1`, `serie_2` y `serie_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_1 = pd.Series([1,2,3], index= list('abc'))\n",
    "serie_2 = pd.Series([4,5], index= list('cd'))\n",
    "serie_3 = pd.Series([6,7,8,9], index= list('efgh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.concat()` actua de la manera esperada en este caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([serie_1,serie_2,serie_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que se entrega una lista con las series como argumento. `pd.concat()` permite seleccionar eje de concatenacion. En este caso, el valor por defecto es `join = 'outer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se entrega el argumento sort=False para evitar un warning inocuo\n",
    "pd.concat([serie_1,serie_2,serie_3], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si por otra parte se entrega el parámetro `join ='inner'`, se tendrá la intersección de las 3 series (que es nula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([serie_1, serie_2, serie_3], axis=1, sort=False, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si por otra parte, solo se concatenan la series 1 y 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([serie_1,serie_2], axis=1, sort=False, join = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene lo esperado, esto sugiere que se concatenan solo aquellas columnas donde no se deba insertar `NaN`.\n",
    "\n",
    "**Ejercicios**\n",
    "\n",
    "1. El argumento `keys` de la función `pd.concat()` permite crear un dataframe con multi - indices. Utilice las series `serie_1`, `serie_2` y `serie_3` y `keys` con el argumento `['s1', 's2, 's3']`. Observe que al concatenar por columnas, las llaves anteriores pasan a ser etiquetas de columna.\n",
    "\n",
    "2. Utilice los dataframes `df_m` y `df_n` de la sección pasada. Utilice el parámetro `keys = [df_m, df_n]`, genere un nuevo dataframe:\n",
    "    1. Concatenando por fila para unión interna y externa. \n",
    "    2. Concatenado por columna para unión interna y externa\n",
    "¿Como cambia el papel del parámetro `keys`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de la concatenación de dataframes, se siguen los mismos patrones.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se crean 2 dataframes y se concatenan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(1,9).reshape(4, 2),\n",
    "                   index=list('abcd'),\n",
    "                   columns=['W', 'X'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(10*np.arange(4).reshape(2, 2),\n",
    "                   index=['a', 'c'],\n",
    "                   columns=['Y', 'Z'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se concatenan por filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se concatenan por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se concatenan usando columnas multi nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2], axis=1, sort=False , keys = ['df1', 'df2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Concatene `df1` y `df2` agregando un multi indice con niveles superiores dados por 'df1_idx' y 'df2_idx'. \n",
    "\n",
    "2. Genere dos dataframes a partir de matrices aleatorias de dimensión 3 x 4 y 2 x 3. Agregue columnas, de manera tal que las etiquetas del segundo dataframe estén contenidas en las del primero. Cuando se trabaja con dataframes, cuya información referente al indice no es relevante, se puede utilizar el argumento `ingnore_index = True`. Explore esta opción con los dataframes recién creados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En alguna ocasiones puede ser util reemplazar valores faltantes en un conjunto de datos, basándose en un segundo dataset. En este contexto, si hay coincidencia en índices y columnas, es posible 'parchar' información utilizando métodos de combinación de pandas. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se crean 2 dataframes con información faltante, para eso se utilizan los dataframes `df_n` y `df_m`. En primer lugar, se definen las posiciones a alterar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_m = [(1,1),(0,2),(2,2)]\n",
    "pos_n = [(0,0),(0,2),(1,1),(2,1),(3,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se alteran de manera iterativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos in pos_m: df_m.iloc[pos] = np.nan\n",
    "for pos in pos_n: df_n.iloc[pos] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestran los cambios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se desea completar información en los espacios de `df_n` basándose en la información con mismos pares (índice,columna), la función de merge no nos sirve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_n,df_m, how = 'inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera, concatenar (aunque sea con inner joint) agrega filas o columnas a `df_n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_n,df_m],sort=False, join='inner', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_n,df_m],sort=False, join='inner', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correcta forma de añadir tal información es por medio del método `.combine_first()` y en conjunción con `.drop()`. En efecto, se 'parchan' los valores faltantes pero se agrega la columna `data_m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.combine_first(df_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina tal columna por medio de `.drop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.combine_first(df_m).drop('data_m', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos con `df_n` antes de combinar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada esta funcionalidad, es que hace importante tener consistencia en los indices y columnas de datasets con información relacionada. De esa forma, se puede simplificar el proceso de integración de bases y limpieza de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rearreglos\n",
    "\n",
    "Dentro de las operaciones más comunes se encuntra el reordenado *reshape* de arreglos. En este contexto, existen las opciones `stack` y `unstack`. \n",
    "\n",
    "* `stack` permite utilizar las columnas como pivote. Genera un indexado jerárquico, moviendo las columnas al indexado como nivel superior.\n",
    "\n",
    "* `unstack` utiliza los indices como pivote. Genera un indexado jerárquico de columnas moviendo los indices al sector de columnas como nivel superior.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se define un dataframe con indexado jerárquico, se opera sobre el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi = pd.DataFrame(100 * np.arange(6).reshape((2, 3)),\n",
    "                     index=['A', 'B'],\n",
    "                     columns=['C1', 'C2', 'C3'])\n",
    "df_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica `stack`, observe como se genera una 'rotación' del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica `unstack`, observe como rota en sentido opuesto a `stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mi.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. ¿Qué tipo de objeto se obtiene al realizar stacking?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comportamiento en dataframes con multi - indexado (en filas o columnas) consiste en pivotear sobre el nivel más interno, trasladándolo hacia filas o columnas nuevamente, posicionandolas en el nivel más interno.\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "Para comprender el funcionamiento de `stack` y `unstack`, es más sencillo implementarlo. Para ello:\n",
    "\n",
    "1. Defina un dataframe multi indexado. Para ello, concatene el resultado de `df_mi.unstack()` por columna y asignelo a la variable `df_s`. Ejecute `stack` y `unstack` sobre tal dataframe. **Obs:** Ambas ordenes son mutuamente inversas, por lo que concatenarlas siginifica no modificar el dataframe.\n",
    "\n",
    "Como se vio, el comportamiento de `stack` y `unstack` de manera predeterminada es seleccionar los niveles más internos para pivotear. Se puede cambiar dicho comportamiento entregando un nivel. \n",
    "\n",
    "2. Genere un dataframe multi-indexando en filas y columnas. Para esto, ejecute:\n",
    "    1. `df_s = pd.concat([df_s,df_s - 100], axis = 1)`\n",
    "    2. `df_s = df_mi.unstack()`\n",
    "    3. `df_s = pd.concat([df_s,df_s - 100], axis = 1)`\n",
    "    4. `df_q = df_s.stack()`\n",
    "    5. `df_q = pd.concat([df_q, df_q + 100, 0.2 * df_q], axis=1)`\n",
    "    6. `df_q.columns = [['D1', 'D1', 'D2'], [1, 2, 3]]`\n",
    "\n",
    "3. Ejecute `df_q.stack()` intente predecir su funcionamiento, repita el proceso con `df_q.unstack()`. ¿Se deberian introducir valores faltantes en alguno de estos casos?\n",
    "\n",
    "4. Ejecute `df_q.stack({i})` donde `{i}` puede ser 0 o 1. ¿Qué representan estos números?\n",
    "\n",
    "5. Ejecute `df_q.stack({i})` donde `{i}` puede ser 0,1 o 2. ¿Qué representan estos números? ¿Por qué en este caso se puede llegar hasta 2?\n",
    "\n",
    "5. Investigue le parametro 'drop_na' de ambos métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupaciones \n",
    "\n",
    "La categorización de dataset facilita la exploración y transformación de los datos. Por lo general, los procesos de categorización y agrupamiento de datasets se ven envueltos en 3 *meta - procesos*: el primero es la *separación*, que corresponde a dividir un dataset en grupos basándose en *queries* o filtrado de algún tipo. Posteriormente se *aplica* (siguiente fase) alguna transformación a los componentes de la separación producida, para finalmente *combinar* (ultima fase) los resultados a un objeto final. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se carga el dataset de ranking de universidades. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/timesData.csv', index_col=['year', 'world_rank'])\n",
    "df.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca calcular el puntaje `total_score` promedio para las universidades en el primer puesto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello, es necesario limpiar la variable `total_score` pues es considerada como un valor 'string'. Esto ocurre pues posee valores faltantes denotados por '-'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reemplazan los valores faltantes agregando NaN.\n",
    "df['total_score'].replace('-',np.nan, inplace=True)\n",
    "df['total_score'] = df['total_score'].apply(float)\n",
    "\n",
    "# Se adquiere la media del puntaje, puede ser mejor reemplazar por knn\n",
    "mean = df['total_score'].mean()\n",
    "\n",
    "# Se llenan los valores faltantes\n",
    "df.fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, se procede a agrupar `df` por ranking, es decir, los valores de ranking serán los indexadores para generar un nuevo dataframe. Esto se hace por medio del método `.groupby()`. En dataframes multi - indexados, este método permite elegir el nivel sobre el cual se desea agrupar los datos. En este caso, el nivel correspondiente a 'world_rank' es 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto resultante es una agrupación del tipo `DataFrameGroupBy`. Esta clase representa una regla de agrupación asocidada a un objeto de pandas, sobre este tipo de agrupaciones, se puede realizar calculos. \n",
    "\n",
    "Puede ser útil hacer una analogia entre los objetos `DataFrameGroupBy` y los iterators. Un iterator posee una regla de iteración que solo se aplica cuando se llama el método `__next__`, por su parte, un objeto `DataFrameGroupBy`representa una regla de agrupación, que se concreta cuando se aplica una transformación (agregación) sobre tal agrupación. \n",
    "\n",
    "Volviendo al ejemplo, no tiene sentido agrupar los valores por ranking si no se proporciona una regla de qué irá escrito en cada celda de la tabla, es decir, si no se proporciona un método de reducción, se tendrían que mostrar 6 valores distintos por celda, uno por cada año, para cada columna del dataframe. \n",
    "\n",
    "Finalmente, efectuamos la operación de agregación `.mean()` sobre la agrupación producida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(level=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se desean obtener solo los resultados asociados a la columna 'total_score' ejecutamos `df['total_score'].groupby(level=1).mean()` para seleccionar solo el ranking 1, se ejecuta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Equivalente a \n",
    "\n",
    "df['total_score'].groupby(level=1).mean()[0] \n",
    "\n",
    "pues df['total_score'] es una serie!\n",
    "'''\n",
    "\n",
    "df['total_score'].groupby(level=1).mean().loc['1'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se quisiera agrupar por ranking y pais de origen, se puede aplicar selección de columnas por medio de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by = ['country','world_rank']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que ahora 'world_rank' está contabilizado junto a las columnas por las cuales agrupar, aún cuando es un (multi) índice. Si se quiere elegir solo el puntaje total, se debe tener en cuenta que el objeto resultante (post agregación) es un dataframe. Luego, se puede hacer lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by = ['country','world_rank']).mean()['total_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Es posible iterar sobre agrupaciones de datos\n",
    "\n",
    "1. Genere una discretización de 'total_score' en 4 categorias: entre 0 y 25, entre 25 y 50, entre 50 y 75 y entre 75 y 100. Agregue tal discretización como una columna de nombre 'score_bin'.\n",
    "\n",
    "2. Agrupe el conjunto de datos según año y score_bin. El objetivo se este ejercicio es que imprima en pantalla la información agrupada por año, extrayendo los nombres de sus universidades. Para ello:\n",
    "    1. Itere con un ciclo for sobre la agrupación generada utilizanzdo `i` como única variable de iteración. ¿Cuantas variables de iteración soporta la agrupación ? ¿por que?\n",
    "    2. Imprima el intervalo inspeccionado por `i`.\n",
    "    3. Imprima el nombre de la universidad para el pais inspeccioando por `i`. Debería ser capaz de obtener en pantalla información de la forma:\n",
    "    \n",
    "    ```    \n",
    "    Intervalo:  (25, 50] \n",
    "\n",
    "    year  world_rank\n",
    "    2011  165                               University of Amsterdam\n",
    "          165                               University of Liverpool\n",
    "          167                                     Aarhus University\n",
    "          168                                   University of Leeds\n",
    "          168                                University of Würzburg\n",
    "          170                               University of Groningen       \n",
    "    ```\n",
    "3. El método `.get_group()` de un objeto `DataFrameGroupBy` permite consultar por información similar a la impresa en pantalla. Ejecute la agrupación `df.groupby(by = ['year','score_bin'])` y luego aplique el método `.get_group((2011,intervalo))` donde intervalo es un objeto `pd.Interval` con valores adecuados para representar el intervalo '(25, 50]'.\n",
    "\n",
    "**Obs**: Más allá de imprimir valores en pantalla, iterar sobre agrupaciones permite más flexibilidad de agregación sobre los datos agrupados, además de prestar herramientas para concatenación y generación de nuevos datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible agrupar por funciones o mapeos sobre los indices o columnas con las que queramos agrupar. \n",
    "\n",
    "Por ejemplo, si se desea añadir un nivel extra de agrupación sobre índices, es posible hacer con un *mapeo de relaciones*, este tiene la forma de un diccionario que permite emular el comportamiento de un índice multinivel, este puede ser utilizado en columnas con la opción `axis=1` o en índices con la opción de `axis` por defecto.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se define el mapeo dado por las relaciones:\n",
    "\n",
    "* research, citations $\\to$ desarrollo\n",
    "* teaching, student_staff_ratio $\\to$ docencia\n",
    "\n",
    "Se hace por medio del diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'research': 'Desarrollo',\n",
    "    'citations': 'Desarrollo',\n",
    "    'teaching': 'Docencia',\n",
    "    'student_staff_ratio': 'Docencia'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reconstruyen los índices para que los datos se agrupen por año y universidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.set_index(['year','university_name'], inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que se hace una agrupación en las columnas, por lo tanto si se desean ver resultados por año y ranking, es necesario agregar los datos por el eje `axis = 1`, en caso contrario, los valores presentes en la agrupación pasan a ser indices, como no se puede proporcionar un método de agregación al mapeo, esto resulta en un conjunto de indices vacío y por tanto en una agreción vacia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['teaching', 'research', 'citations', 'total_score',\n",
    "    'student_staff_ratio']].groupby(mapping, axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se logra agrupar a las universidades por items de desarrollo y doncencia, indexadas por año. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Una forma automática de generar mapeos es por medio de funciones, en este caso, el método `.groupby()` puede recibir una función $f(\\cdot)$, esta función se aplica sobre los índices $i$ que formarán la nueva agrupación, generando nuevos índices de la forma $i_{mod} = f(i)$.\n",
    "\n",
    "1. Defina la función `score_cat()`, esta función opera sobre una variable `score` de tipo `float` entre 0 y 100, retorna `'Buena'` si si `score < 75` y `Excelente` en caso contrario. \n",
    "\n",
    "2. Redefina el indice de `df` para que sea `'total_score`. \n",
    "\n",
    "3. Genere una agregación por fila sobre las columnas numéricas de `df`,  de tal manera que los índices sean las categorías de puntaje total `Buena`, `Excelente` y que se muestre el promedio para cada categoría para las variables numéricas. *Hint*: Use `.groupby()` entregando como argumento la función `score_cat`, agregue por promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo métodos `.sum()` , `.count()`, `.mean()`, `.std()` y `.var()` (entre otros) son agregaciones comunes implementadas por pandas. Todas forman parte de un método `.agg()`\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se implementa una función propia de agregación, estas deben operar sobre arreglos y entregar un valor como resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_agg(vec, phase = np.pi/2):\n",
    "    '''Calcula la media de una transformacion coseno sobre vec.\n",
    "    \n",
    "    La transformacion es cos(phase*(vec**2)). \n",
    "    \n",
    "    Args:\n",
    "        vec: np.array, pd.Series\n",
    "             Vector a transformar\n",
    "        \n",
    "        phase: numeric (opcional)\n",
    "               Parametro de la transfromacion coseno  \n",
    "    \n",
    "    Returns:\n",
    "        media: numeric\n",
    "               Entrega el promedio de la transformacion coseno aplicada \n",
    "               componente a componente.\n",
    "    \n",
    "    '''\n",
    "    return np.mean(np.cos(phase*vec**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se forma un índice jerárquico basádo en año y nombre de universidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.set_index(['year', 'university_name'], inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se genera una agrupación por ranking y se agrega usando la función creada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('world_rank').agg(cos_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.agg()` acepta el nobre de una fucnión como string (solo con funciones de agregación implementadas por default). Se agrupa por media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('world_rank').agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, se puede proporcionar una lista de funciónes, en formato string o puro. En tal caso se realiza una agregación por función entregada sobre el dataframe agregando un multinivel donde sea necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('world_rank').agg([cos_agg,'mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Al proporcionar una lista de funciones para agregar, pandas asigna nombres de manera automática a los niveles de indexado. ¿Qué ocurre con las funciones anónimas (lambda)?\n",
    "\n",
    "1. Defina una función anónima de agregación. Puede refactorizar la función `cos_agg` transformándola en función anónima por ejemplo.\n",
    "\n",
    "2. Agregue los datos utilizando la función recien construida sobre la agrupación por `'world_rank'` realizada anteriormente. ¿Qué ocurre con el nombre de la columna multi-indexada?\n",
    "\n",
    "3. Entregue tuplas a `.agg` donde en la primera compnente se entrega el nombre la columna a multi-indexar, haga esto para su función anónima y para `'mean'`. Asignando los nombres 'cos_mean' y 'media' respectivamente.\n",
    "\n",
    "4. Se pueden aplicar grupos de transformaciones por columna de agrupación, para ello se utilizan dicionarios de la forma `{'columna':'agregacion'}`. En la agrupación por `'world_rank` agregue los datos  `'teaching'`  por media y los de `'research'` por `cos_agg`.\n",
    "\n",
    "5. Es posible tener múltiples agregaciones por columna, para eso se utilizan diccionarios de la forma:\n",
    "```python\n",
    "{'col_1': [func_11, func_21, ...,func_n1], \n",
    " 'col_2': [func_21, func_22, ...,func_n2],\n",
    "     ...\n",
    " 'col_m':[func_nm, func_nm, ...,func_nm]} \n",
    "```\n",
    "Agregue la columna `'teaching'` por minimo máximo y media, por otra parte agrege `'research'` por desviación estándar y `cos_agg`. ¿Cómo se pueden agregar nombres a estas agregaciones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se discutió, los pasos del proceso de agregación consisten en separar, aplicar y combinar. `.groupby()` permite **separar** los datos generando un iterable sobre el cual se puede operar, `.agg()` **aplica** una función al objeto agrupado y finalmente los **combina** en un daframe. \n",
    "\n",
    "Si bien el comando de agregación `.agg()` presenta una gran flexbilidad en los procesos de *aplicación* y *combinación*, pandas ofrece una capa un poco más abstracta dada por el método `.apply()`. Este método *separa*, aplica y combina por medio de concatenación.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se trabaja con el dataframe anterior (ranking de universidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que, a diferencia de agregar en un único valor (como lo hae la media por ejemplo) queremos obtener una lista ordenada de elementos por medio de una función, es posible definir una función para luego aplicarla sobre el dataframe.\n",
    "\n",
    "En este caso, se buscan los mejores `n` puntajes, promediados por año, para una columna `col` determinada. Se desean mostrar los resultados por universidad, para ello, se define para ello la función `top_n_col()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_col(df, n = 3, col = 'total_score'):\n",
    "    '''Entrega los top n elementos de df.[col].'''\n",
    "    \n",
    "    # Agrupa por universidad y agrega por promedio\n",
    "    grouped = df.groupby(level=1).mean()\n",
    "    \n",
    "    # retorna los mejores n valores para la columna deseada\n",
    "    return grouped.sort_values(by = col)[-n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica la función al dataframe `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_col(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si se deseara agregar los resultados anteriores por pais, se puede hacer utilizando la el método `.apply()` sobre una agrupación por pais de `df`, en efecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('country').apply(top_n_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hace `.apply()` en este caso es generar sub-dataframes para cada valor de la columna agrupada `'country'` en este caso, el primer sub - dataframe es el asociado a 'Argentina' y se accede a el por medio de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['country'] == 'Argentina']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si sobre aquel sub - dataframe *aplicamos* `top_n_col()` se observa el resultado de la primera fila anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_col(df[df['country'] == 'Argentina'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, pasa al siguiente sub-dataframe (en este caso dado por 'Australia'), repite el calculo y concatena los resultados. Al recorrer cada valor de `'country'` termina generando el dataframe obtenido anteriormente.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "A continuación se estudia una aplicación de agregación de datos, esta consiste **en llenado de datos faltantes por grupo**. En primer lugar se carga la base de universidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/timesData.csv', index_col=['year','university_name'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estudian los valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.replace(to_replace='-',value=np.nan, inplace=True)\n",
    "\n",
    "print('Porcentaje de valores faltantes')\n",
    "(df.isnull().sum()/len(df))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que la columna `'total_score'` posee una alta cantidad de valores faltantes, por otra parte, las columnas `'income'` y `'female_male_ratio'` tiene menos de un 10% valores faltantes y \n",
    "`'num_students'`, `'international'`, `'student_staff_ratio'` e `'international_students'` tienen en torno al 2% de valores faltantes. Se forman 3 grupos.\n",
    "\n",
    "El primer grupo será constituido por `'num_students'`, `'international'`, `'student_staff_ratio'` e `'international_students'`, la estrategia para llenar sus valores faltantes será por promedio. Para ello, es necesario convertir los datos a formato `'float'`. En el caso de `'num_students'` esto requiere un preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reemplazan comas por puntos\n",
    "df['num_students'].replace(',', '.', regex=True, inplace=True)\n",
    "\n",
    "# Se transforman los datos a formato float\n",
    "df['num_students'] = df['num_students'].apply(float)*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para `'international_students'` se requiere transformar porcentajes a formato numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se quitan los simbolos %\n",
    "df['international_students'].replace('%', '', regex=True, inplace=True)\n",
    "\n",
    "# Se transforman los datos a formato float\n",
    "df['international_students'] = df['international_students'].apply(float)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para 'female_male_ratio' es necesario transformar el formato `xx : yy` a procentaje del tipo `xx/100`.  Para ello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se busca un patron de la forma _:_xx y se elimina, aquí _ representa \n",
    "un espacio y se anota por \\ , el simbolo : se mantiene y [0-9]*\n",
    "representa numeros de la forma x_0 x_1 x_2, ..., x_n donde x_i \n",
    "representa un digito, la instrucción * dice repetir busqueda \n",
    "[0-9] (de digitos) hasta agotar el caracter inspeccionado.\n",
    "'''\n",
    "\n",
    "df['female_male_ratio'].replace('\\ :\\ [0-9]*', '', regex=True, inplace=True)\n",
    "df['female_male_ratio'] = df['female_male_ratio'].apply(float)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el resto de las columnas no hay problema. Se procede a construir los grupos y se transforman los valores a formato numerico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'num_students': 'grupo_1',\n",
    "    'international': 'grupo_1',\n",
    "    'student_staff_ratio': 'grupo_1',\n",
    "    'international_students': 'grupo_1',\n",
    "    'income': 'grupo_2',\n",
    "    'female_male_ratio': 'grupo_2',\n",
    "    'total_score': 'grupo_3'\n",
    "}\n",
    "\n",
    "# Columnas a agrupar\n",
    "cols = list(groups.keys())\n",
    "\n",
    "# Transformación a datos flotanes\n",
    "df[cols] = df[cols].applymap(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se normalizan las variables para tener consistencia en los promedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['international'] = df['international']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = H.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para estas variables se decide normalizar por minimo y maximo \n",
    "def normalizer(vec):\n",
    "    '''Normaliza por minimo y maximo al vector vec.'''\n",
    "    \n",
    "    m = vec.min()\n",
    "    M = vec.max()\n",
    "    \n",
    "    return (vec - m)/(M-m)\n",
    "    \n",
    "df['student_staff_ratio'] = normalizer(df['student_staff_ratio'])\n",
    "df['num_students'] = normalizer(df['num_students'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a extraer las medias del grupo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[cols].groupby(groups, axis=1).mean()['grupo_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para llenar los valores de este grupo, se genera la función `fill_mean` que llena los valores faltantes de un dataset utilizando su promedio. Esto en conjunción con `.apply()` permite llenar los valores faltantes para un grupo seleccionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se extraen los elementos del grupo 1\n",
    "grupo_1 = {key:val for key,val in gropus.items() if val == 'grupo_1'}\n",
    "grupo_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la función `fill_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mean(df):\n",
    "    return df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a llenar los valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[grupo_1.keys()].groupby(grupo_1, axis=1).apply(fill_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio** \n",
    "\n",
    "1. Llene los valores faltantes de los otros dos grupos de variables, siguiendo un esquema de agregado diseñado por usted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, pandas ofrece una herramienta de *tablas pivote*, estas agregan los datos al proporcionar una o más llaves, generando un arreglo rectangular con llaves de agrupación en indices y columnas. \n",
    "\n",
    "Las tablas pivote se hacen por medio de `.groupby()` combinando indexación y reshaping. Estos métodos se resumen en la función `pd.pivot_table()` tambien disponible como el método `pivot_table`. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se toma la base de ranking de universidades y se genera una tabla pivote proporcionando un indice jarárquico consistente de 'country' en el nivel superior y 'university_name' en el nivel inferior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index = ['country', 'university_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si en la tabla anterior se desea agregar los datos de 'total_score' se sigue la sintaxis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table('total_score',index = ['country', 'university_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se desea hacer por puntaje total y puntaje de enseñanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(['total_score', 'teaching'],\n",
    "               index=['country', 'university_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible agregar calculos por columna por medio de funciones de agregación, por defecto esta es el promedio. La opción a utilizar es `'margins'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(['total_score', 'teaching'],\n",
    "               index=['country', 'university_name'], margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para elegir otra función de agregación, se usa `aggfunc`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejericio**\n",
    "\n",
    "1. Genere una tabla pivote muli-inidce donde la función de agregación sea la moda y se llenen los valores faltantes con el valor -1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda Parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementos de Visualización en Python\n",
    "\n",
    "Lograr visualizaciones (plots) informativas es de gran importancia en análisis de datos. Su aplicación en este campo es transversal, abarcando desde la parte exploratoria, para por ejemplo, identificación de outliers o búsqueda de transformaciones en las variables. Por otra parte, las visualizaciones son una manera natural de mostrar los resultados obtenidos y facilitar la interpretación de los fenómenos estudiados. En Python existen librerías capaces de producir visualizaciones de manera intuitiva tanto estáticas como dinámicas, en este ámbito, la librería raíz es `matplotlib`. Tal librería está diseñada para la creación de visualizaciones de alta calidad para publicaciones. \n",
    "\n",
    "\n",
    "`Matplotlib` puede exportar visualizaciones en formatos vectorizados y comprimidos como son PDF, SVG, JPG, PNG, GIF , entre otros. Existe una extensa variedad de librerías gráficas basadas en `matplotlib`, una de ellas es `seaborn`, la cual también se explora en este capítulo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación y primeros pasos \n",
    "\n",
    "Como con NumPy y Pandas, existe una convención a la hora de importar esta librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:09:34.094153Z",
     "start_time": "2018-08-14T05:09:33.716828Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:09:34.235143Z",
     "start_time": "2018-08-14T05:09:34.096124Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.arange(10)\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar de manera interactiva, la linea mágica:\n",
    "```\n",
    "%matplotlib notebook\n",
    "\n",
    "```\n",
    "Toma provecho de las capacidades del proyecto Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:11.632551Z",
     "start_time": "2018-08-14T05:10:11.561278Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuras y subplots\n",
    "\n",
    "Las visualizaciones `plots` en matplotlib actúan dentro de un objeto más general denominado figura o `figure`. Es posible crear un objeto `figure` vacío para luego agregar las visualizaciones deseadas a través de:\n",
    "\n",
    "```python\n",
    "fig = plt.figure()\n",
    "\n",
    "```\n",
    "Esto genera una ventana vacía, no obstante, es posible modificar opciones del objeto `fig` declarado anteriormente. Dentro de estas opciones se encuentra `figsize` la cual permite indicar el tamaño y relación de aspecto al momento de almacenar la visualización en el disco.\n",
    "\n",
    "Para insertar visualizaciones dentro de la figura recién creada, es necesario añadir un `subplot`, el método `add_subplot` permite agregar múltiples visualizaciones a la figura en la cual se invoca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:20.322500Z",
     "start_time": "2018-08-14T05:10:20.309746Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:09:34.407669Z",
     "start_time": "2018-08-14T05:09:34.356868Z"
    }
   },
   "outputs": [],
   "source": [
    "ax1 = fig.add_subplot(2,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando anterior indica que la figura tiene una estructura que comprende 2 visualizaciones por fila y 2 por columna, es decir la figura comprenderá 4 subfiguras de las cuales se selecciona la primera y se almacena como `ax1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "* Agregue 2 subfiguras a la figura `fig`. estas deben estar en la esquina superior derecha e inferior izquierda. Denote estas subfiguras como `ax2` y `ax3`.\n",
    "\n",
    "Observación: En Jupyter, los plots se reinician luego de cada evaluación de celda, por lo tanto para obtener el esquema de subfiguras solicitado, debe declarar la figura y todos los subplots en la misma celda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al agregar un comando de visualización como por ejemplo:\n",
    "```pyhton\n",
    "plt.plot([-1,1,-1,1])\n",
    "```\n",
    "matplotlib modificará la última figura creada en su último subplot, en caso de ser una figura vacía, se creará un nuevo subplot en ella. Por lo tanto, al evaluar el código anterior, se deberá agregar una figura con forma de \"N\" en el último subplot del ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:29.018460Z",
     "start_time": "2018-08-14T05:10:29.009721Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot([-1,1,-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, es posible añadir visualizaciones en los demás subplots usando las variables antes almacenadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:30.530246Z",
     "start_time": "2018-08-14T05:10:30.519320Z"
    }
   },
   "outputs": [],
   "source": [
    "ax2.plot(np.random.randn(10), 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tal caso, se indicó generar el gráfico de una variable aleatoria normal estándar, de la cual se extraen 10 muestras. El comando `r--` indica que el gráfico debe ser rojo, con líneas \"cortadas\" y posicionado en el subplot `ax2`.\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "* Genere un arreglo aleatorio de dimensión 100, explore con tal arreglo  el método `hist`. ¿Qué función cumple el parámetro `alpha`?\n",
    "\n",
    "* Estudie el método `scatter`. ¿En qué se diferencia al método `plot`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra manera de obtener figuras compuestas de subplots es a través del método `plt.subplots`, este entrega como `return` una figura y un arreglo NumPy con los objetos `subplot` en su interior:\n",
    "```python\n",
    "fig, axes = plt.subplots(2,3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:36.459312Z",
     "start_time": "2018-08-14T05:10:36.250872Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:09:34.791043Z",
     "start_time": "2018-08-14T05:09:34.787534Z"
    }
   },
   "outputs": [],
   "source": [
    "axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a la variable `axes` esta presenta la facilidad de ser accedida como un arreglo de dos dimensiones, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:39.284051Z",
     "start_time": "2018-08-14T05:10:39.280302Z"
    }
   },
   "outputs": [],
   "source": [
    "axes[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permite acceder al primer subplot de la segunda columna de la figura `fig`.\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "* Utilice la notación anterior para graficar solo en los subplots correspondientes a la esquina inferior izquierda y esquina superior derecha.\n",
    "\n",
    "* Una opción bastante útil es la de mantener la misma escala en cada subplot de la figura creada. Explore las opciones `sharex` y `sharey`. ¿Cómo se comporta matplotlib al no indicar estas opciones ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustes de espaciado en subplots\n",
    "\n",
    "Por defecto, matplotlib maneja de manera automática el espacio alrededor de cada subplot. Esto se hace de manera relativa y en función a las dimensiones de la figura, sin embargo, es posible modificar esta opción utilizando `subplots_adjust` en objetos del tipo `Figure`:\n",
    "\n",
    "```python\n",
    "subplots_adjust(left=None, bottom=None, right=None, top=None,wspace=None, hspace=None)\n",
    "``` \n",
    "\n",
    "En este contexto, las variables `wspace` y `hspace` controlan el porcentaje de ancho (width) y alto (height) que se debe utilizar entre subplots. \n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "* Genere una figura con 4 histogramas, todas las subfiguras deben estar adyacentes unas con otras (no debe haber espacio entre ellas). (Hint: genere los histogramas usando 2 ciclos `for` anidados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:41.980806Z",
     "start_time": "2018-08-14T05:10:41.779929Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[i, j].hist(np.random.randn(500), color='k', alpha=0.5)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colores, marcadores y estilos de línea\n",
    "\n",
    "La función de visualización principal de matplotlib `plot` permite ingresar arreglos de coordenadas `x` e `y`, en este caso, para producir un gráfico color verde con líneas o \"dashes\" se puede ingresar un arreglo `X` y un arreglo `Y` ambos de la misma dimensión y ejecutar:\n",
    "\n",
    "```python\n",
    "ax.plot(X,Y,'g--')\n",
    "```\n",
    "\n",
    "Donde `ax` es un subplot antes declarado. La notación anterior es una versión comprimida de las opciones `linesyle='--'` y `color='g'` de tal manera que el comando anterior equivale a ingresar:\n",
    "\n",
    "```python\n",
    "ax.plot(X,Y,linestyle = '--', color = 'g')\n",
    "```\n",
    "\n",
    "**Ejericio** \n",
    "\n",
    "* Compruebe lo antes descrito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:44.653973Z",
     "start_time": "2018-08-14T05:10:44.648245Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.arange(10)\n",
    "Y = X + np.random.randn(10)\n",
    "\n",
    "fig = plt.plot(X,Y,linestyle = '--', color = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En matplotlib es posible personalizar los colores que se desea obtener en un gráfico, los colores más usados poseen su propia abreviación por ejemplo `'g'` se refiere a verde, `'k'` a negro, `'r'` a rojo, etc ...\n",
    "\n",
    "Si se desea ser aún más especifico, es posible ingresar un código hex para el color que se desea visualizar:\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "* Cambie el color del gráfico anterior por uno en código hex de su elección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente los plots pueden tener *marcadores* para resaltar las coordenadas correspondientes a los datos. Esto, debido a que la función `plot` genera una línea continua entre los puntos que se ingresan, por tanto, puede aparecer la necesidad de especificar las ubicaciones de los datos reales proporcionados. Los marcadores se acceden a través de la opción `marker` de la función `plot`, la siguiente [referencia](https://matplotlib.org/api/markers_api.htmlreferencia) proporciona los marcadores disponibles. Se puede acceder también a la notación simplificada utilizando por ejemplo:\n",
    "\n",
    "```python\n",
    "plt.plot(np.random.randn(30).cumsum(), 'ko-')\n",
    "```\n",
    "Donde el marcador es 'o' el color es negro y el tipo de línea es continuo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:46.696912Z",
     "start_time": "2018-08-14T05:10:46.690179Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.random.randn(30).cumsum(), 'ko-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, la interpretación entre los puntos del gráfico es hecha de manera lineal, esto se puede personalizar con la opción `drawstyle`, la siguiente [referencia](https://matplotlib.org/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D.set_drawstyle) muestra los tipos de interpolación disponibles. \n",
    "\n",
    "En el siguiente ejemplo se especifica además la etiqueta o `label` de cada \"línea\" graficada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:50.229424Z",
     "start_time": "2018-08-14T05:10:50.216485Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.random.randn(30).cumsum()\n",
    "\n",
    "plt.plot(data, 'ro--', label='Default')\n",
    "plt.plot(data, 'k-' , drawstyle='steps-post', label='steps-post')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final del ejemplo se ejecuta el comando `legend`, el cual indica que se de deben mostrar los objetos del tipo `label` declarados con la opción `label` en la función `plot`. En el caso de graficar sobre un subplot `ax` se puede llamar el método `ax.legend`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejes, etiquetas y leyendas\n",
    "\n",
    "\n",
    "Para personalizar los valores mostrados en el eje `x`, es posible usar las opciones `set_xticks` y `set_xticklabels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:54.915969Z",
     "start_time": "2018-08-14T05:10:54.865589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Genera una serie aleatoria\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(np.random.randn(500).cumsum())\n",
    "\n",
    "# Selecciona los puntos de interes en el eje x\n",
    "ticks = ax.set_xticks([0, 36,150, 225, 453])\n",
    "\n",
    "\n",
    "# Cambia los nombres de los valores en el eje\n",
    "\n",
    "labels = ax.set_xticklabels(['cero','A','B','X','W'], rotation=30, fontsize='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T13:18:22.898983Z",
     "start_time": "2018-07-30T13:18:22.896545Z"
    }
   },
   "source": [
    "Es también posible agregar un titulo a la visualización, para ello se llama la función`set_title`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:57.602873Z",
     "start_time": "2018-08-14T05:10:57.598040Z"
    }
   },
   "outputs": [],
   "source": [
    "ax.set_title('Titulo de prueba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "* Utilice el método `set_xlabel` para dar un nombre al eje `x` del plot anterior.\n",
    "\n",
    "\n",
    "Modificar el eje `y` consiste en el mismo procedimiento antes descrito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Los objetos definidos por el método `add_subplots` se denominan `axes`, estos, como clase, poseen el método `set` que permite ingresar sus propiedades a través de un diccionario. En el caso anterior es posible configurar el subplot `ax` por medio de:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:10:59.545528Z",
     "start_time": "2018-08-14T05:10:59.541194Z"
    }
   },
   "outputs": [],
   "source": [
    "ops = {\n",
    "    'title':'Titulo de prueba',\n",
    "    'xlabel':'Ejercicio'\n",
    "}\n",
    "\n",
    "ax.set(**ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe indicar el diccionario antes descrito utilizando como llaves los campos que se deseen ingresar, además se debe utilizar doble asterisco `**` al llamar el método `set`, esto pues la declaración de tal método recibe un diccionario con variables \"identificadas por nombre\" como entrada. En declaración de funciones esto se denota con el uso de variables `**kwargs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leyendas\n",
    "\n",
    "Las leyendas corresponden al elemento principal de identificación de gráficos. Anteriormente se utilizó esta opción, en esta sección se estudia con más detalle.\n",
    "\n",
    "La manera más sencilla de agregar una leyenda, cosiste en primero crear una etiqueta pasando la opción `label` al crear la visualización de interés para luego llamar el método `legend`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:01.879732Z",
     "start_time": "2018-08-14T05:11:01.800222Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "from numpy.random import randn\n",
    "fig = plt.figure(); ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.plot(randn(100).cumsum(),'r'  , label='G_1')\n",
    "ax.plot(randn(100).cumsum(),'k--', label='G_2')\n",
    "ax.plot(randn(100).cumsum(),'g.-' , label='G_3')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es de esperar, el método `legend` tiene opciones adicionales para, por ejemplo, controlar la posición de las legendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:03.858421Z",
     "start_time": "2018-08-14T05:11:03.850530Z"
    }
   },
   "outputs": [],
   "source": [
    "ax.legend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotaciones y figuras sobre un subplot\n",
    "\n",
    "Hasta ahora, las visualizaciones generadas corresponden a figuras más bien estándar. En caso de querer agregar anotaciones adicionales, consistentes de texto, flechas u otras formas, es posible usar los métodos `text`, `arrow` y `annotate`. \n",
    "\n",
    "`text` genera un texto en las coordenadas (x,y) a elección, este método también presenta opciones extras sobre el estilo:\n",
    "\n",
    "```python\n",
    "ax.text(10,5,'Anotación Cepal', family='monospace', fontsize='10')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:07.665462Z",
     "start_time": "2018-08-14T05:11:07.660435Z"
    }
   },
   "outputs": [],
   "source": [
    "ax.text(70,5,'Anotación Cepal', family='monospace', fontsize='10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las anotaciones pueden también dibujar flechas con texto informativo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de añadir anotaciones, es posible agregar figuras, las figuras principales se denominan `patches`, alguno de estos son los rectángulos y círculos, en la documentación de `matplotlib.patches` se hace una recopilación de estos. A continuación se muestra un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:29.536775Z",
     "start_time": "2018-08-14T05:11:29.481165Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "rect = plt.Rectangle((0.2, 0.75), 0.4, 0.15, color='k', alpha=0.3)\n",
    "circ = plt.Circle((0.7, 0.2), 0.15, color='b', alpha=0.3)\n",
    "pgon = plt.Polygon([[0.15, 0.15], [0.35, 0.4], [0.2, 0.6]],\n",
    "color='g', alpha=0.5)\n",
    "ax.add_patch(rect)\n",
    "ax.add_patch(circ)\n",
    "ax.add_patch(pgon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de figuras\n",
    "\n",
    "Es posible almacenar en el disco las figuras producidas, para ello, el método `plt.savefig` es usado. Por ejemplo, para almacenar una figura en formato `SVG` con el nombre `figura_text` se puede hacer con comando:\n",
    "```python\n",
    "plt.savefig('.../ruta/figura_test.SVG')\n",
    "\n",
    "```\n",
    "\n",
    "El tipo de archivo se infiere automáticamente de la extensión usada, los tipos de archivos soportados incluyen `png` y `pdf` entre otros. Algunas opciones de bastante utilidad son `dpi` y `bbox_inches`, el siguiente comando permite guardar un figura en formato `png` con 400 dpi y con el mínimo espacio alrededor del gráfico:\n",
    "\n",
    "```python\n",
    "plt.savefig('figpath.png', dpi=400, bbox_inches='tight')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de matplotlib\n",
    "\n",
    "El paquete descrito hasta acá viene preconfigurado con esquemas de colores. Todos estos esquemas \"por defecto\" pueden ser personalizados extendiendo los parámetros globales de la librería. El método `rc`  permite hacer esto, por ejemplo, para cambiar el tamaño de las figura a 10x10 se puede ingresar:\n",
    "\n",
    "```python\n",
    "plt.rc('figure', figsize=(10,10))\n",
    "```\n",
    "\n",
    "El primer argumento de `rc` es el componente que se desea personalizar, en este caso es `figure`, se puede acceder también a `axes`, `xtick`, `ytick`, `grid`, `legend` entre otros. Luego se ingresan los parámetros que se deseen modificar, esto puede ser hecho a través de diccionarios:\n",
    "\n",
    "```python\n",
    "opt = {'family' : 'monospace',\n",
    "       'weight' : 'bold',\n",
    "       'size' : 'small'}\n",
    "plt.rc('font', **opt)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaciones con Pandas y seaborn\n",
    "\n",
    "matplotlib se puede interpretar como una herramienta de \"bajo nivel\" para la producción de visualizaciones, es decir, esta se generan a partir de sus componentes básicos.\n",
    "\n",
    "En Pandas por otra parte, los DataFrames pueden tener múltiples columnas además de etiquetas para las filas. Este paquete posee métodos de visualización incluidos, pensados para simplificar el proceso de producción a partir de Series y DataFrames. \n",
    "\n",
    "Otra librería basada en tal principio es `seaborn`, esta corresponde a una librería de gráficos estadísticos construida sobre matplotlib. A continuación se estudian las posibilidades de visualización tanto en pandas como en seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos de línea\n",
    "\n",
    "Las Series y Dataframes poseen atributo `plot`, este permite hacer gráficas simples, por defecto, este atributo genera gráficos de línea interpolados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga la base de ranking de universidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:33.555925Z",
     "start_time": "2018-08-14T05:11:33.498535Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/timesData.csv', index_col=['year', 'university_name'])\n",
    "df_to_plot = df.groupby(level=0).mean()\n",
    "\n",
    "fig = plt.figure()\n",
    "s = df_to_plot['research']\n",
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los indices del objeto serie son interpretados como el eje `x`, esto se puede evitar con `use_index = False`. El los puntos de interés en `x` o \"ticks\" y sus limites se pueden ajustar por medio de `xticks` y `xlim`, de la misma manera se puede ajustar el eje `y`. Las opciones disponibles se pueden acceder en la documentación del `plot`.\n",
    "\n",
    "Por lo general, lo métodos de visualización en pandas permiten un parámetro `ax` el cual puede ser un subplot de matplotlib. \n",
    "\n",
    "El método `plot` en DataFrames genera un plot distinto para cada visualización produciendo una \"linea\" distinta por columna además de generar una leyenda de manera automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:42.359458Z",
     "start_time": "2018-08-14T05:11:42.349629Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_plot.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por su parte, el método `plot` de un DataFrame, posee opciones diferentes a las de una Serie, siendo `subplots` una de estas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:48.516452Z",
     "start_time": "2018-08-14T05:11:48.373279Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_plot.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos de barra\n",
    "\n",
    "La función `plot.bar()` y `plot.barh()` generan gráficos de barra verticales y horizontales respectivamente. En esta caso, los índices ya sean de la Serie o DataFrame serán utilizados como el eje `x` (bar) o `y` (barh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:51.365780Z",
     "start_time": "2018-08-14T05:11:51.123864Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1)\n",
    "data = pd.Series(np.random.rand(16), index=list('abcdefghijklmnop'))\n",
    "\n",
    "data.plot.bar(ax=axes[0], color='k', alpha=0.7)\n",
    "data.plot.barh(ax=axes[1], color='k', alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las opciones `color = 'k'` y `alpha=0.7` proporcionan tanto el color como la transparencia de las barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:52.989440Z",
     "start_time": "2018-08-14T05:11:52.899286Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.rand(6, 4),\n",
    "\n",
    "index=['one', 'two', 'three', 'four', 'five', 'six'],\n",
    "columns=pd.Index(['A', 'B', 'C', 'D'], name='Titulo - personalizado'))\n",
    "\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear gráficos de barra superpuestos a partir de un DataFrame la opción `stacked=True` lo permite de manera sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:55.298645Z",
     "start_time": "2018-08-14T05:11:55.200897Z"
    }
   },
   "outputs": [],
   "source": [
    "df.plot.barh(stacked=True, alpha=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio** \n",
    "\n",
    "* Genere un gráfico de barras horizontal, donde se muestren las frecuencias para los puntajes promedio de 'research' separados en 5 bins. (Hint: `value_counts` con la opcion bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer visualizaciones que requieran un agrupamiento previo exhaustivo de los datos, es posible usar `seaborn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:11:59.193263Z",
     "start_time": "2018-08-14T05:11:59.096704Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig=plt.figure()\n",
    "\n",
    "sns.barplot(data=df_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El argumento de barplot corresponde a un DataFrame u observaciones de una base de datos en arreglos `x` e `y`. En este caso, el gráfico corresponde a los valores promedio de los puntajes 'teaching', 'research', 'citations' y 'student_staff_ratio'. Además agrega un intervalo de confianza del 95% al valor (lineas negras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible cambiar el estilo de los gráficos usando el método `set` de seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:12:06.208377Z",
     "start_time": "2018-08-14T05:12:06.203045Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramas y gráficos de densidad\n",
    "\n",
    "Un histograma es un tipo de gráfico de barras que proporciona un valor discretizado de las frecuencias. Para esto, se discretizan los valores presentes en la base de datos para luego ser separados en \"bins\", posteriormente se gráfica el número de veces que un bin es \"poblado\" por algún elemento de la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:12:07.831016Z",
     "start_time": "2018-08-14T05:12:07.721474Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_plot.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tipo relacionado de datos son los gráficos de densidad, estos calculan una estimación de la distribución de probabilidad que pudo haber generado los datos. El procedimiento usual para esto, es aproximar tal distribución por medio de una mezcla de \"kernels\", es decir, distribuciones más simples. Por tanto, los gráficos de densidad son conocido con el nombre de estimadores de densidad por kernels o KDE por sus siglas en ingles. Usando la función `plot.kde`  se puede obtener un KDE usando una mezcla de distribuciones normales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:12:11.174122Z",
     "start_time": "2018-08-14T05:12:10.844519Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_plot.plot.density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn produce histogramas y gráficos de densidad de manera aún más sencilla a través del método `distplot`, el cual genera tanto un histograma como un KDE continuo (de manera simultanea). A modo de ejemplo, se consideran dos distribuciones conocidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:12:12.725026Z",
     "start_time": "2018-08-14T05:12:12.721222Z"
    }
   },
   "outputs": [],
   "source": [
    "comp1 = np.random.normal(0, 1, size=200)\n",
    "comp2 = np.random.normal(10, 2, size=200)\n",
    "values = pd.Series(np.concatenate([comp1, comp2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:12:13.916995Z",
     "start_time": "2018-08-14T05:12:13.774870Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "#sns.distplot(values, bins=100, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos de dispersión\n",
    "\n",
    "Los gráficos compuestos de \"puntos\" o gráficos de dispersión puede ser una manera útil de examinar la relación entre datos 2-dimensionales. Por ejemplo, en los datos analizados en la `clase 1` se hace uso de tal ventaja:\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "* Utilice la función `sns.regplot()` sobre `df_to_plot['research']` como eje 'y' y `df_to_plot.index` como eje x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pudo haber observado, tal función ajusta una regresión lineal sobre un gráfico de dispersión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra herramienta importante en análisis de datos es la opción de analizar las relaciones entre las distintas variables que intervienen en el fenómeno que se estudia. Esto se puede hacer mediante el estudio de *gráficos de pares* o una **matriz de gráficos de dispersión**. Es posible generar gráficos de con tales características desde cero usando matplotlib, sin embargo, seaborn posee la función **pairplot** que soporta histogramas y KDE's de cada variable en la diagonal de la *matriz*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:12:22.289253Z",
     "start_time": "2018-08-14T05:12:21.946796Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_to_plot, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, es posible ingresar argumentos en forma de diccionario a través de la opción `plots_kws`, por ejemplo, si se quisiera agregar cierta transparencia: \n",
    "```python\n",
    "sns.pairplot(arg_1, arg_2,...,plot_kws={'alpha': 0.2})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grillas y datos categóricos\n",
    "\n",
    "Una manera de visualizar datos con múltiples variables categóricas es usando un \"grilla de facetas\". En seabron existe la función `factorplot` que simplifica la tarea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:12:24.892508Z",
     "start_time": "2018-08-14T05:12:24.433740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se carga la base de ejemplo \"tips\" presente como\n",
    "# dataset de ejemplo en seaborn.\n",
    "\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip'])\n",
    "\n",
    "sns.factorplot(x='day', y='tip_pct', hue='time', col='smoker',\n",
    "               kind='bar', data=tips[tips.tip_pct < 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vez de agrupar por `time` usando colores distintos colores de barras, se puede expandir una \"grilla de facetas\" agregando una fila por valor de `time`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T05:12:27.361103Z",
     "start_time": "2018-08-14T05:12:26.900972Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x='day', y='tip_pct', row='time', col='smoker',\n",
    "                  kind='bar', data=tips[tips.tip_pct < 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`factorplot` soporta también otros tipos de gráficos que pueden ser útiles dependiendo de la que se desee mostrar. Por ejemplo los gráficos de caja:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "* Estudie el tipo de gráfico conocido domo 'violin'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 123.18181799999999,
   "position": {
    "height": "40px",
    "left": "1344.62px",
    "right": "20px",
    "top": "142px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
